# ---- vLLM on V100 (compute 7.0) ----
# Compatible with Tesla V100 GPUs (cc 7.0)
FROM nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04

ARG DEBIAN_FRONTEND=noninteractive
ARG PIP_DISABLE_PIP_VERSION_CHECK=1

# System deps
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip python3-dev git ca-certificates curl \
    && rm -rf /var/lib/apt/lists/*

# Ensure python and pip point to python3
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3 1 \
 && update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    TORCH_CUDA_ARCH_LIST="7.0" \
    VLLM_USE_FLASH_ATTENTION="0" \
    VLLM_NO_FLASH_ATTENTION="1" \
    NVIDIA_VISIBLE_DEVICES=all \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility

# ---- Python packages ----
RUN pip install --upgrade pip setuptools wheel \
 && pip install --extra-index-url https://download.pytorch.org/whl/cu121 \
    torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2

# vLLM (version pinned for compatibility)
ARG VLLM_VERSION=0.3.3
RUN pip install \
    "vllm==${VLLM_VERSION}" \
    "transformers>=4.41,<4.46" \
    "accelerate>=0.29" \
    "huggingface_hub>=0.22" \
    "sentencepiece" \
    "einops"

# Non-root user
ARG USER=app
ARG UID=10001
RUN useradd -m -u ${UID} -s /bin/bash ${USER}
USER ${USER}
WORKDIR /workspace

EXPOSE 8000 8100

# Entrypoint allows Compose to inject runtime args like --model, --host, --port
ENTRYPOINT ["python", "-m", "vllm.entrypoints.openai.api_server"]
CMD ["--help"]



CFG="config.json"

# backup first
cp "$CFG" "${CFG}.bak"

# set max context = 8192, rope_scaling disabled
jq '.rope_scaling = null | .max_position_embeddings = 8192' "$CFG" > "$CFG.tmp" \
  && mv "$CFG.tmp" "$CFG"



curl http://127.0.0.1:8100/v1/completions \
  -H "Content-Type: application/json" \
  -d '{
        "model": "/models/Llama-3.1-8B-Instruct",
        "prompt": "What is the capital of France?",
        "max_tokens": 100
      }'
